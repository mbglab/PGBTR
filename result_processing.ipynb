{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# For the results of unsupervised learning methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc , f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T06:58:29.412038500Z",
     "start_time": "2024-01-24T06:58:25.771235900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  [0.8504818560766341, 0.8483333386641595, 0.848342178671017, 0.8493075911383642, 0.8498945003710914, 0.8507160262280669, 0.849152842808585, 0.8518333045068592, 0.8505528468032194, 0.8477747256625907] \t 0.8496 ± 0.0012\n",
      "AUPRC:  [0.8781890883237036, 0.8768638649096492, 0.8761150757085192, 0.8777577858395167, 0.8770144454060433, 0.8782892638228252, 0.8756082165460825, 0.8786924352624809, 0.8770634852218734, 0.876829644683528] \t 0.8772 ± 0.0009\n",
      "f1-score:  [0.7617763248524522, 0.7610295929693888, 0.7645172931043008, 0.761527880349173, 0.7615261720003131, 0.7620235279052517, 0.7632694784494518, 0.7637686974975746, 0.7630201018908483, 0.7585362929272839] \t 0.7621 ± 0.0016\n"
     ]
    }
   ],
   "source": [
    "# AGRN\n",
    "ETR_result = pd.read_csv('result/Dream5_Silico/AGRN/ETR.csv', index_col=0)\n",
    "RFR_result = pd.read_csv('result/Dream5_Silico/AGRN/RFR.csv', index_col=0)\n",
    "\n",
    "gene_list = pd.read_csv('data/Dream5/Network1_Silico/net1_gene_ids.tsv', sep='\\t',index_col=1)\n",
    "\n",
    "final_auroc = []\n",
    "final_auprc = []\n",
    "final_f1 = []\n",
    "for iter_num in range(1, 11):\n",
    "    auroc_list = []\n",
    "    auprc_list = []\n",
    "    f1_list = []\n",
    "    for num in range(5):\n",
    "        # test data in supervised methods\n",
    "        test_data = pd.read_csv(f'data/Dream5/Network1_Silico/processed_balanced/{iter_num}/test_data{num}.txt', sep='\\t',header=None)\n",
    "        test_data.columns = ['TF', 'target', 'Index']\n",
    "\n",
    "        for  i in range(test_data.shape[0]):\n",
    "            ### RegulonDB_Ecoli and Bsubtilis dataset ###\n",
    "            #tf_id = gene_list.loc[test_data.loc[i, 'TF'], '#ID']\n",
    "            #tg_id = gene_list.loc[test_data.loc[i, 'target'], '#ID']\n",
    "            ### dream5 dataset ###\n",
    "            tf_id = test_data.loc[i, 'TF']\n",
    "            tg_id = test_data.loc[i, 'target']\n",
    "            all_id = tf_id+'_'+tg_id\n",
    "            if all_id in ETR_result.index:\n",
    "                test_data.loc[i, 'importance'] = (ETR_result.loc[all_id, \"shap_Proba\"]+RFR_result.loc[all_id, \"shap_Proba\"])/2\n",
    "        test_data.dropna(inplace=True)\n",
    "        true_labels = np.array(test_data.Index)\n",
    "        predicted_probs = np.array(test_data.importance)\n",
    "        predicted_labels = (predicted_probs >= np.median(predicted_probs)).astype(int)\n",
    "        auroc = roc_auc_score(true_labels, predicted_probs)\n",
    "        precision, recall, _ = precision_recall_curve(true_labels, predicted_probs)\n",
    "        auprc = auc(recall, precision)\n",
    "        f1 = f1_score(true_labels, predicted_labels)\n",
    "        auroc_list.append(auroc)\n",
    "        auprc_list.append(auprc)\n",
    "        f1_list.append(f1)\n",
    "    final_auroc.append(np.mean(auroc_list))\n",
    "    final_auprc.append(np.mean(auprc_list))\n",
    "    final_f1.append(np.mean(f1_list))\n",
    "\n",
    "print('AUROC: ', final_auroc, '\\t', '{:.4f}'.format(np.mean(final_auroc)),'±','{:.4f}'.format(np.std(final_auroc)))\n",
    "print('AUPRC: ', final_auprc, '\\t', '{:.4f}'.format(np.mean(final_auprc)),'±','{:.4f}'.format(np.std(final_auprc)))\n",
    "print('f1-score: ', final_f1, '\\t', '{:.4f}'.format(np.mean(final_f1)),'±','{:.4f}'.format(np.std(final_f1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:13:59.549047700Z",
     "start_time": "2024-01-22T09:13:43.863359500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  [0.8210760629515835, 0.8175540088274639, 0.8159637779773672, 0.8185205227429575, 0.8209814231536194, 0.8217093450271259, 0.8186578444721381, 0.8189993388587677, 0.8201903460275439, 0.820135393643687] \t 0.8194 ± 0.0017\n",
      "AUPRC:  [0.852641689616199, 0.8499732843425161, 0.8504585717113814, 0.8521417759236322, 0.85368471941962, 0.8546539496487439, 0.8509884068394074, 0.8508659346299726, 0.8512918942172872, 0.8536043562069061] \t 0.8520 ± 0.0015\n",
      "f1-score:  [0.7474795119806561, 0.7408269569273782, 0.7378819456297065, 0.7420578779268202, 0.7451673973332167, 0.7445717839319099, 0.7377100431764481, 0.7410674221587581, 0.7435689608893911, 0.7411748498583174] \t 0.7422 ± 0.0030\n"
     ]
    }
   ],
   "source": [
    "# GENIE3\n",
    "GENIE3_result = pd.read_csv('result/Dream5_Silico/GENIE3/Dream5_Silico_infer_net1.tsv', sep='\\t')\n",
    "GENIE3_result.set_index(['TF','target'],inplace=True)\n",
    "\n",
    "final_auroc = []\n",
    "final_auprc = []\n",
    "final_f1 = []\n",
    "for iter_num in range(1,11):\n",
    "    auroc_list = []\n",
    "    auprc_list = []\n",
    "    f1_list = []\n",
    "    for num in range(5):\n",
    "        test_data = pd.read_csv(f'data/Dream5/Network1_Silico/processed_balanced/{iter_num}/test_data{num}.txt', sep='\\t',header=None)\n",
    "        test_data.columns = ['TF', 'target', 'Index']\n",
    "        test_data.drop_duplicates(inplace=True)\n",
    "        test_data.set_index(['TF','target'],inplace=True)\n",
    "        idx = [x for x in test_data.index if x in GENIE3_result.index]\n",
    "        tmp = GENIE3_result.loc[idx]\n",
    "        result = pd.concat([tmp, test_data.loc[idx]], axis=1)\n",
    "        true_labels = np.array(result.Index)\n",
    "        predicted_probs = np.array(result.importance)\n",
    "        predicted_labels = (predicted_probs >= np.median(predicted_probs)).astype(int)\n",
    "        auroc = roc_auc_score(true_labels, predicted_probs)\n",
    "        precision, recall, _ = precision_recall_curve(true_labels, predicted_probs)\n",
    "        auprc = auc(recall, precision)\n",
    "        f1 = f1_score(true_labels, predicted_labels)\n",
    "        auroc_list.append(auroc)\n",
    "        auprc_list.append(auprc)\n",
    "        f1_list.append(f1)\n",
    "    final_auroc.append(np.mean(auroc_list))\n",
    "    final_auprc.append(np.mean(auprc_list))\n",
    "    final_f1.append(np.mean(f1_list))\n",
    "\n",
    "print('AUROC: ', final_auroc, '\\t', '{:.4f}'.format(np.mean(final_auroc)),'±','{:.4f}'.format(np.std(final_auroc)))\n",
    "print('AUPRC: ', final_auprc, '\\t', '{:.4f}'.format(np.mean(final_auprc)),'±','{:.4f}'.format(np.std(final_auprc)))\n",
    "print('f1-score: ', final_f1, '\\t', '{:.4f}'.format(np.mean(final_f1)),'±','{:.4f}'.format(np.std(final_f1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:15:26.123256200Z",
     "start_time": "2024-01-22T09:15:21.450415400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  [0.7933116703277567, 0.7885059546578936, 0.7914066393628727, 0.7901122352889589, 0.7892746929457752, 0.7881698725363868, 0.7897587562167274, 0.7888587332363495, 0.7917038129080487, 0.7888905540083295] \t 0.7900 ± 0.0016\n",
      "AUPRC:  [0.8392142335043806, 0.8360959556410428, 0.839118018523271, 0.8364503470794826, 0.835938751655485, 0.8347881752605556, 0.8354785926949357, 0.8364063182027944, 0.8382145594766388, 0.8359128931892382] \t 0.8368 ± 0.0015\n",
      "f1-score:  [0.7144300335121005, 0.710941246914526, 0.7129388974656232, 0.714180967122624, 0.7126848641132705, 0.7121870428578949, 0.7149281657105747, 0.7116913947213375, 0.7169219353744727, 0.7114406209504657] \t 0.7132 ± 0.0018\n"
     ]
    }
   ],
   "source": [
    "# PROTIA\n",
    "protia_result = np.array(pd.read_csv('result/Dream5_Silico/PROTIA/Dream5_Silico.csv', index_col=0))\n",
    "gene_list = pd.read_csv('data/Dream5/Network1_Silico/net1_gene_ids.tsv', sep='\\t',index_col=1)\n",
    "\n",
    "final_auroc = []\n",
    "final_auprc = []\n",
    "final_f1 = []\n",
    "for iter_num in range(1, 11):\n",
    "    auroc_list = []\n",
    "    auprc_list = []\n",
    "    f1_list = []\n",
    "    for num in range(5):\n",
    "        test_data = pd.read_csv(f'data/Dream5/Network1_Silico/processed_balanced/{iter_num}/test_data{num}.txt', sep='\\t',header=None)\n",
    "        test_data.columns = ['TF', 'target', 'Index']\n",
    "\n",
    "        for  i in range(test_data.shape[0]):\n",
    "            ### RegulonDB_Ecoli and Bsubtilis dataset ###\n",
    "            #tf_id = int(gene_list.loc[test_data.loc[i, 'TF'], '#ID'][1:]) - 1\n",
    "            #tg_id = int(gene_list.loc[test_data.loc[i, 'target'], '#ID'][1:]) - 1\n",
    "            ### Dream5 dataset ###\n",
    "            tf_id = int(test_data.loc[i, 'TF'][1:]) - 1\n",
    "            tg_id = int(test_data.loc[i, 'target'][1:]) - 1\n",
    "            test_data.loc[i, 'importance'] = protia_result[tf_id, tg_id]\n",
    "\n",
    "        true_labels = np.array(test_data.Index)\n",
    "        predicted_probs = np.array(test_data.importance)\n",
    "        predicted_labels = (predicted_probs >= np.median(predicted_probs)).astype(int)\n",
    "        auroc = roc_auc_score(true_labels, predicted_probs)\n",
    "        precision, recall, _ = precision_recall_curve(true_labels, predicted_probs)\n",
    "        auprc = auc(recall, precision)\n",
    "        f1 = f1_score(true_labels, predicted_labels)\n",
    "        auroc_list.append(auroc)\n",
    "        auprc_list.append(auprc)\n",
    "        f1_list.append(f1)\n",
    "    final_auroc.append(np.mean(auroc_list))\n",
    "    final_auprc.append(np.mean(auprc_list))\n",
    "    final_f1.append(np.mean(f1_list))\n",
    "\n",
    "print('AUROC: ', final_auroc, '\\t', '{:.4f}'.format(np.mean(final_auroc)),'±','{:.4f}'.format(np.std(final_auroc)))\n",
    "print('AUPRC: ', final_auprc, '\\t', '{:.4f}'.format(np.mean(final_auprc)),'±','{:.4f}'.format(np.std(final_auprc)))\n",
    "print('f1-score: ', final_f1, '\\t', '{:.4f}'.format(np.mean(final_f1)),'±','{:.4f}'.format(np.std(final_f1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:21:14.401145500Z",
     "start_time": "2024-01-22T09:21:01.595257400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
